{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a12c8f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.22607609629631042,\n",
       "  'token': 6979,\n",
       "  'token_str': ' int',\n",
       "  'sequence': 'def returnInt() -> int:'},\n",
       " {'score': 0.1578385978937149,\n",
       "  'token': 5053,\n",
       "  'token_str': ' Any',\n",
       "  'sequence': 'def returnInt() -> Any:'},\n",
       " {'score': 0.1569618135690689,\n",
       "  'token': 9291,\n",
       "  'token_str': ' None',\n",
       "  'sequence': 'def returnInt() -> None:'},\n",
       " {'score': 0.12274535745382309,\n",
       "  'token': 1907,\n",
       "  'token_str': ' type',\n",
       "  'sequence': 'def returnInt() -> type:'},\n",
       " {'score': 0.06580983847379684,\n",
       "  'token': 1666,\n",
       "  'token_str': '...',\n",
       "  'sequence': 'def returnInt() ->...:'}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaConfig, RobertaTokenizer, RobertaForMaskedLM, pipeline\n",
    "import torch\n",
    "\n",
    "model = RobertaForMaskedLM.from_pretrained(\"microsoft/codebert-base-mlm\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base-mlm\")\n",
    "\n",
    "CODE = \"def returnInt() -> <mask>:\"\n",
    "fill_mask = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n",
    "\n",
    "outputs = fill_mask(CODE)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b176b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(torch.nn.Module):\n",
    "    def __init__(self, model, d, vocabulary_size = 50265): \n",
    "        super(CustomModel, self).__init__() \n",
    "        self.d = d\n",
    "        self.model = model\n",
    "        self.config = model.config\n",
    "        self.layer = torch.nn.Linear(vocabulary_size, d)\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None):\n",
    "        model_output = self.model.forward(input_ids=input_ids, attention_mask=attention_mask)        \n",
    "        final_output_tensor = self.layer.forward(model_output[0])\n",
    "        model_output.logits = final_output_tensor\n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4dcb017f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 50265])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl_tokens=tokenizer.tokenize(\"\")\n",
    "code_tokens=tokenizer.tokenize(\"def returnInt() -> blahblah\")\n",
    "tokens=[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]+code_tokens+[tokenizer.sep_token]\n",
    "tokens_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
    "model(torch.tensor(tokens_ids)[None,:])[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "88841175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[-1.5327,  1.6024, -3.1271, -1.6551, -2.2588, -0.2849,  2.3658,\n",
       "           3.5348],\n",
       "         [-0.8810,  0.8842, -3.3689, -1.4831, -1.7109, -0.4538,  1.2516,\n",
       "           3.4641],\n",
       "         [-0.1972,  1.8971, -5.9111, -0.9745, -0.7997,  0.1484,  1.2759,\n",
       "           1.6533],\n",
       "         [-0.4901,  1.4421, -3.8161, -1.2706, -2.7123,  2.3424,  0.4357,\n",
       "           3.1755],\n",
       "         [-1.8994,  1.4675, -1.9338, -3.1568, -3.7597, -1.4410,  1.3943,\n",
       "           5.7186],\n",
       "         [-2.5603, -0.4156, -4.5737, -2.9418, -0.9588, -2.8346,  1.6243,\n",
       "           6.9443],\n",
       "         [-3.2496,  2.7400, -3.1106, -5.1585, -2.7332,  0.5180,  2.1054,\n",
       "           7.4531],\n",
       "         [-0.2799, -0.9783, -2.5475, -2.1471, -3.5733,  3.7248, -0.3224,\n",
       "           4.1424],\n",
       "         [-0.1317, -0.1612, -4.8593, -2.6546,  2.1494, -0.1348, -0.2017,\n",
       "           4.6845],\n",
       "         [ 0.4310, -0.0933, -4.4425, -3.5494, -2.8485, -0.0183, -0.6244,\n",
       "           4.3259],\n",
       "         [-1.5258,  1.6011, -3.1276, -1.6646, -2.2606, -0.2842,  2.3675,\n",
       "           3.5232]]], grad_fn=<AddBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model = CustomModel(model, 8)\n",
    "custom_model.forward(torch.tensor(tokens_ids)[None,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8d518b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8491508364677429,\n",
       "  'token': 2,\n",
       "  'token_str': '</s>',\n",
       "  'sequence': 'def returnInt() ->:'},\n",
       " {'score': 0.061621226370334625,\n",
       "  'token': 6,\n",
       "  'token_str': ',',\n",
       "  'sequence': 'def returnInt() ->,:'},\n",
       " {'score': 0.05688280612230301,\n",
       "  'token': 4,\n",
       "  'token_str': '.',\n",
       "  'sequence': 'def returnInt() ->.:'},\n",
       " {'score': 0.027118658646941185,\n",
       "  'token': 5,\n",
       "  'token_str': ' the',\n",
       "  'sequence': 'def returnInt() -> the:'},\n",
       " {'score': 0.0028568394482135773,\n",
       "  'token': 1,\n",
       "  'token_str': '<pad>',\n",
       "  'sequence': 'def returnInt() ->:'}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model = CustomModel(model, 8)\n",
    "fill_mask = pipeline('fill-mask', model=custom_model, tokenizer=tokenizer)\n",
    "\n",
    "outputs = fill_mask(CODE)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c65e6177",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def calc_euclidean(self, x1, x2):\n",
    "        return (x1 - x2).pow(2).sum(1)\n",
    "    \n",
    "    def forward(self, anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor) -> torch.Tensor:\n",
    "        distance_positive = self.calc_euclidean(anchor, positive)\n",
    "        distance_negative = self.calc_euclidean(anchor, negative)\n",
    "        losses = torch.relu(distance_positive - distance_negative + self.margin)\n",
    "\n",
    "        return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bf172749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed83a6ded4224e4fa422004ad12500dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def tokenize_code(code):\n",
    "    nl_tokens = tokenizer.tokenize(\"\")\n",
    "    code_tokens = tokenizer.tokenize(code)\n",
    "    tokens = [tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]+code_tokens+[tokenizer.sep_token]\n",
    "    tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    return torch.tensor(tokens_ids)[None,:]\n",
    "\n",
    "epochs = 1\n",
    "data = [(\"def returnInt() -> <mask>:\", \"def calcInt() -> <mask>:\",\"def returnFloat() -> <mask>:\", \"int\")]\n",
    "\n",
    "optimizer = torch.optim.Adam(custom_model.parameters(), lr=0.001)\n",
    "criterion = torch.jit.script(TripletLoss())\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "    custom_model.train()\n",
    "    running_loss = []\n",
    "    for step, (t_a, t_p, t_n, anchor_label) in enumerate(data):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        anchor_out = custom_model(tokenize_code(t_a))\n",
    "        positive_out = custom_model(tokenize_code(t_p))\n",
    "        negative_out = custom_model(tokenize_code(t_n))\n",
    "        \n",
    "        loss = criterion(anchor_out[0], positive_out[0], negative_out[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2ec5e128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9662728905677795,\n",
       "  'token': 3,\n",
       "  'token_str': '<unk>',\n",
       "  'sequence': 'def returnInt() ->:'},\n",
       " {'score': 0.03372710570693016,\n",
       "  'token': 5,\n",
       "  'token_str': ' the',\n",
       "  'sequence': 'def returnInt() -> the:'},\n",
       " {'score': 2.3076533851260636e-16,\n",
       "  'token': 4,\n",
       "  'token_str': '.',\n",
       "  'sequence': 'def returnInt() ->.:'},\n",
       " {'score': 2.2461171363397533e-18,\n",
       "  'token': 7,\n",
       "  'token_str': ' to',\n",
       "  'sequence': 'def returnInt() -> to:'},\n",
       " {'score': 7.931263707988504e-23,\n",
       "  'token': 2,\n",
       "  'token_str': '</s>',\n",
       "  'sequence': 'def returnInt() ->:'}]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask = pipeline('fill-mask', model=custom_model, tokenizer=tokenizer)\n",
    "\n",
    "outputs = fill_mask(CODE)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c35cbd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from annoy import AnnoyIndex\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "KNN_TREE_SIZE = 20\n",
    "\n",
    "def compute_validation_loss_dsl():\n",
    "    with torch.no_grad():\n",
    "        # model.eval()\n",
    "        computed_embed_batches_train = []\n",
    "        computed_embed_labels_train = []\n",
    "        # for step, (t_a, t_p, t_n, anchor_label) in enumerate(DataLoader(data)):\n",
    "        output = custom_model.forward(torch.tensor(tokens_ids)[None,:])\n",
    "        computed_embed_batches_train.append(output.logits.cpu().numpy()) # 11 * 8\n",
    "        # computed_embed_labels_train.append(t_a[1].logits.cpu().numpy())\n",
    "             \n",
    "        annoy_index = create_knn_index(np.vstack(computed_embed_batches_train), None, computed_embed_batches_train[0].shape[2])\n",
    "    return annoy_index\n",
    "\n",
    "def create_knn_index(train_types_embed: np.array, valid_types_embed: np.array, type_embed_dim:int) -> AnnoyIndex:\n",
    "    \"\"\"\n",
    "    Creates KNNs index for given type embedding vectors, taken from Type4Py\n",
    "    \"\"\"\n",
    "\n",
    "    annoy_idx = AnnoyIndex(type_embed_dim, 'euclidean')\n",
    "\n",
    "    for i, v in enumerate(tqdm(train_types_embed, total=len(train_types_embed), desc=\"KNN index\")):\n",
    "        annoy_idx.add_item(i, v[0])\n",
    "\n",
    "    # if valid_types_embed is not None:\n",
    "    #     for i, v in enumerate(valid_types_embed):\n",
    "    #         annoy_idx.add_item(len(train_types_embed) + i, v)\n",
    "\n",
    "    annoy_idx.build(KNN_TREE_SIZE)\n",
    "    return annoy_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8ac93ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b10046047a4522990f6a64b8c39593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KNN index:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<annoy.Annoy object at 0x0000013BA5E38A30>\n"
     ]
    }
   ],
   "source": [
    "annoy_idx = compute_validation_loss_dsl()\n",
    "print(annoy_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "113df0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.5693102e+01 -2.5255030e+01 -1.6359529e+01  3.6548542e+01\n",
      "    3.3064899e-01  3.5709141e+01 -4.7024246e+01 -3.2363412e+00]\n",
      "  [-1.6196732e+01 -2.7523052e+01 -1.2040886e+01  3.6689110e+01\n",
      "    1.6002575e-01  3.5438446e+01 -4.2520947e+01 -3.1085544e+00]\n",
      "  [-2.7576933e+01 -3.8618401e+01 -2.0782473e+00  3.7252720e+01\n",
      "    1.0839910e-01  4.1041142e+01 -3.6700027e+01 -4.7793503e+00]\n",
      "  [-2.3177340e+01 -4.6333946e+01  4.1112299e+00  3.8342468e+01\n",
      "   -7.1163245e-02  4.6451714e+01 -3.1646967e+01 -3.9649751e+00]\n",
      "  [-2.0026312e+01 -4.2045143e+01  3.4292309e+00  2.9566652e+01\n",
      "    2.4433419e-01  4.5869267e+01 -4.1784382e+01 -4.4153147e+00]\n",
      "  [-2.2947287e+01 -3.4197121e+01 -6.5307174e+00  3.5513668e+01\n",
      "    3.3909369e-01  3.8166130e+01 -3.4583218e+01 -4.0050516e+00]\n",
      "  [-2.3524315e+01 -3.4618809e+01 -4.5251775e+00  3.8357151e+01\n",
      "   -3.8281280e-01  4.2755749e+01 -4.0301003e+01 -3.8047602e+00]\n",
      "  [-1.5997654e+01 -2.5336708e+01 -1.6155655e+01  3.7271442e+01\n",
      "    3.4625167e-01  3.4819809e+01 -4.5939411e+01 -2.5128713e+00]\n",
      "  [-2.1240335e+01 -4.0567574e+01 -1.1531620e+00  3.6527042e+01\n",
      "    1.7046803e-01  4.2275288e+01 -3.5283760e+01 -3.5554974e+00]\n",
      "  [-1.9699028e+01 -3.4006454e+01 -6.1398072e+00  3.4012676e+01\n",
      "    1.1281421e-01  4.3850819e+01 -3.9762306e+01 -3.6139562e+00]\n",
      "  [-1.8420380e+01 -3.5432682e+01 -2.9248130e+00  3.1794386e+01\n",
      "    2.8761411e-02  4.4902859e+01 -3.8684956e+01 -3.1552863e+00]\n",
      "  [-1.7709309e+01 -3.7923401e+01  2.8717237e+00  3.3249615e+01\n",
      "    3.3720887e-01  4.3604355e+01 -3.1864891e+01 -4.0829239e+00]\n",
      "  [-2.3724863e+01 -3.8478188e+01 -1.1132509e+00  3.0656013e+01\n",
      "   -2.0346853e-01  4.2850616e+01 -3.6374229e+01 -4.2488976e+00]\n",
      "  [-2.0352459e+01 -4.0875816e+01  3.1416826e+00  3.3365948e+01\n",
      "    9.1994959e-01  4.3521091e+01 -3.1427040e+01 -4.3621693e+00]\n",
      "  [-2.5746967e+01 -3.7664589e+01 -4.7428765e+00  3.6186386e+01\n",
      "    2.7781650e-01  4.4088184e+01 -4.1640423e+01 -4.4601221e+00]\n",
      "  [-2.3043707e+01 -3.0816572e+01 -6.4652481e+00  3.5930099e+01\n",
      "    1.8540853e-01  4.2663044e+01 -3.9116837e+01 -4.4815655e+00]\n",
      "  [-1.8424889e+01 -3.1628447e+01 -5.8044181e+00  2.9718599e+01\n",
      "    1.3377306e-01  3.8954685e+01 -4.2059944e+01 -5.1969481e+00]\n",
      "  [-2.2213343e+01 -3.7654312e+01 -4.0634613e+00  3.5097290e+01\n",
      "    8.9696568e-01  4.5703991e+01 -3.8512333e+01 -4.2410488e+00]\n",
      "  [-1.6409060e+01 -2.7169067e+01 -1.5578274e+01  3.9322865e+01\n",
      "    1.4713496e-01  3.6403229e+01 -4.6583397e+01 -3.0877674e+00]\n",
      "  [-2.0072123e+01 -3.6053528e+01 -5.2071295e+00  3.3181648e+01\n",
      "    1.2842704e-01  3.8262798e+01 -3.8433170e+01 -3.9330289e+00]\n",
      "  [-2.3736349e+01 -3.8229095e+01 -5.2403078e+00  4.2261566e+01\n",
      "   -7.4322429e-03  4.0777046e+01 -3.7861000e+01 -4.7848554e+00]\n",
      "  [-2.6611061e+01 -3.2153206e+01 -7.4477143e+00  4.1546333e+01\n",
      "   -2.3563635e-01  5.1355190e+01 -5.0438499e+01 -5.1304913e+00]\n",
      "  [-1.4942823e+01 -2.3617985e+01 -1.7656525e+01  3.5094105e+01\n",
      "   -3.0011421e-02  3.2969700e+01 -4.7228291e+01 -2.9118319e+00]]]\n",
      "[[-1.5693102e+01 -2.5255030e+01 -1.6359529e+01  3.6548542e+01\n",
      "   3.3064899e-01  3.5709141e+01 -4.7024246e+01 -3.2363412e+00]\n",
      " [-1.6196732e+01 -2.7523052e+01 -1.2040886e+01  3.6689110e+01\n",
      "   1.6002575e-01  3.5438446e+01 -4.2520947e+01 -3.1085544e+00]\n",
      " [-2.7576933e+01 -3.8618401e+01 -2.0782473e+00  3.7252720e+01\n",
      "   1.0839910e-01  4.1041142e+01 -3.6700027e+01 -4.7793503e+00]\n",
      " [-2.3177340e+01 -4.6333946e+01  4.1112299e+00  3.8342468e+01\n",
      "  -7.1163245e-02  4.6451714e+01 -3.1646967e+01 -3.9649751e+00]\n",
      " [-2.0026312e+01 -4.2045143e+01  3.4292309e+00  2.9566652e+01\n",
      "   2.4433419e-01  4.5869267e+01 -4.1784382e+01 -4.4153147e+00]\n",
      " [-2.2947287e+01 -3.4197121e+01 -6.5307174e+00  3.5513668e+01\n",
      "   3.3909369e-01  3.8166130e+01 -3.4583218e+01 -4.0050516e+00]\n",
      " [-2.3524315e+01 -3.4618809e+01 -4.5251775e+00  3.8357151e+01\n",
      "  -3.8281280e-01  4.2755749e+01 -4.0301003e+01 -3.8047602e+00]\n",
      " [-1.5997654e+01 -2.5336708e+01 -1.6155655e+01  3.7271442e+01\n",
      "   3.4625167e-01  3.4819809e+01 -4.5939411e+01 -2.5128713e+00]\n",
      " [-2.1240335e+01 -4.0567574e+01 -1.1531620e+00  3.6527042e+01\n",
      "   1.7046803e-01  4.2275288e+01 -3.5283760e+01 -3.5554974e+00]\n",
      " [-1.9699028e+01 -3.4006454e+01 -6.1398072e+00  3.4012676e+01\n",
      "   1.1281421e-01  4.3850819e+01 -3.9762306e+01 -3.6139562e+00]\n",
      " [-1.8420380e+01 -3.5432682e+01 -2.9248130e+00  3.1794386e+01\n",
      "   2.8761411e-02  4.4902859e+01 -3.8684956e+01 -3.1552863e+00]\n",
      " [-1.7709309e+01 -3.7923401e+01  2.8717237e+00  3.3249615e+01\n",
      "   3.3720887e-01  4.3604355e+01 -3.1864891e+01 -4.0829239e+00]\n",
      " [-2.3724863e+01 -3.8478188e+01 -1.1132509e+00  3.0656013e+01\n",
      "  -2.0346853e-01  4.2850616e+01 -3.6374229e+01 -4.2488976e+00]\n",
      " [-2.0352459e+01 -4.0875816e+01  3.1416826e+00  3.3365948e+01\n",
      "   9.1994959e-01  4.3521091e+01 -3.1427040e+01 -4.3621693e+00]\n",
      " [-2.5746967e+01 -3.7664589e+01 -4.7428765e+00  3.6186386e+01\n",
      "   2.7781650e-01  4.4088184e+01 -4.1640423e+01 -4.4601221e+00]\n",
      " [-2.3043707e+01 -3.0816572e+01 -6.4652481e+00  3.5930099e+01\n",
      "   1.8540853e-01  4.2663044e+01 -3.9116837e+01 -4.4815655e+00]\n",
      " [-1.8424889e+01 -3.1628447e+01 -5.8044181e+00  2.9718599e+01\n",
      "   1.3377306e-01  3.8954685e+01 -4.2059944e+01 -5.1969481e+00]\n",
      " [-2.2213343e+01 -3.7654312e+01 -4.0634613e+00  3.5097290e+01\n",
      "   8.9696568e-01  4.5703991e+01 -3.8512333e+01 -4.2410488e+00]\n",
      " [-1.6409060e+01 -2.7169067e+01 -1.5578274e+01  3.9322865e+01\n",
      "   1.4713496e-01  3.6403229e+01 -4.6583397e+01 -3.0877674e+00]\n",
      " [-2.0072123e+01 -3.6053528e+01 -5.2071295e+00  3.3181648e+01\n",
      "   1.2842704e-01  3.8262798e+01 -3.8433170e+01 -3.9330289e+00]\n",
      " [-2.3736349e+01 -3.8229095e+01 -5.2403078e+00  4.2261566e+01\n",
      "  -7.4322429e-03  4.0777046e+01 -3.7861000e+01 -4.7848554e+00]\n",
      " [-2.6611061e+01 -3.2153206e+01 -7.4477143e+00  4.1546333e+01\n",
      "  -2.3563635e-01  5.1355190e+01 -5.0438499e+01 -5.1304913e+00]\n",
      " [-1.4942823e+01 -2.3617985e+01 -1.7656525e+01  3.5094105e+01\n",
      "  -3.0011421e-02  3.2969700e+01 -4.7228291e+01 -2.9118319e+00]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393eb1ff533041acbc6494f66d108fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding KNNs & Prediction:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\n",
      "[[(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)], [(3, 1.0)]]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "input_list = [\n",
    "    \"def returnInt() -> <mask>: \\n\\t x: int = 42 \\n\\t return x\",\n",
    "    \"def setInt(self, x: int) -> <mask>: \\n\\t self.x = x\",\n",
    "    \"def getInt(self) -> <mask>: \\n\\t return self.x\",\n",
    "    \"def concatString(self, s1: str, s2: str) -> <mask>: \\n\\t return s1 + s2\",\n",
    "    \"def setStr(self, s: str) -> <mask>: \\n\\t self.s = s\",\n",
    "    \"def getStr(self) -> <mask>: \\n\\t return self.s\",\n",
    "    \"def isInt(self, x) -> <mask>: \\n\\t return x % 1 == 0\",\n",
    "    \"def isString(self, s) -> <mask>: \\n\\t return type(s, str)\"\n",
    "]\n",
    "labels = [\n",
    "    \"int\",\n",
    "    \"int\",\n",
    "    \"int\",\n",
    "    \"str\",\n",
    "    \"str\",\n",
    "    \"str\",\n",
    "    \"bool\",\n",
    "    \"bool\"\n",
    "]\n",
    "\n",
    "def get_test_embedding():\n",
    "    with torch.no_grad():\n",
    "        computed_embed_batches_test = []\n",
    "        computed_embed_labels_test = []\n",
    "        \n",
    "        for i in range(8):\n",
    "            nl_tokens=tokenizer.tokenize(\"\")\n",
    "            code_tokens=tokenizer.tokenize(input_list[i])\n",
    "            tokens=[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]+code_tokens+[tokenizer.sep_token]\n",
    "            tokens_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
    "            \n",
    "            output = custom_model.forward(torch.tensor(tokens_ids)[None,:])\n",
    "            computed_embed_batches_test.append(output.logits.cpu().numpy())\n",
    "#             test_label = tokenizer.convert_tokens_to_ids(tokenizer(labels[i]))\n",
    "#             computed_embed_labels_test.append(labels[i])\n",
    "        return computed_embed_batches_test, labels\n",
    "\n",
    "def predict_type_embed(types_embed_array: np.array, types_embed_labels: np.array, indexed_knn: AnnoyIndex, k: int):\n",
    "    \"\"\"\n",
    "    Predict type of given type embedding vectors\n",
    "    \"\"\"\n",
    "\n",
    "    pred_types_embed = []\n",
    "    pred_types_score = []\n",
    "    for i, embed_vec in enumerate(tqdm(types_embed_array, total=len(types_embed_array), desc=\"Finding KNNs & Prediction\")):\n",
    "        idx, dist = indexed_knn.get_nns_by_vector(embed_vec, k, include_distances=True)\n",
    "        pred_idx_scores = compute_types_score(dist, idx, types_embed_labels)\n",
    "        pred_types_embed.append([i for (i, s) in pred_idx_scores])\n",
    "        pred_types_score.append(pred_idx_scores)\n",
    "    \n",
    "    return pred_types_embed, pred_types_score\n",
    "\n",
    "def compute_types_score(types_dist: list, types_idx: list, types_embed_labels: np.array):\n",
    "        types_dist = 1 / (np.array(types_dist) + 1e-10) ** 2\n",
    "        types_dist /= np.sum(types_dist)\n",
    "        types_score = defaultdict(int)\n",
    "        for n, d in zip(types_idx, types_dist):\n",
    "            types_score[types_embed_labels[n]] += d\n",
    "        \n",
    "        return sorted({t: s for t, s in types_score.items()}.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    \n",
    "types_embed_array, types_embed_labels = get_test_embedding()\n",
    "# print(types_embed_array[0])\n",
    "# print(np.vstack(types_embed_array[0]))\n",
    "knn_K = 8\n",
    "pred_type_embed, pred_type_score = predict_type_embed(np.vstack(types_embed_array[0]), types_embed_labels, annoy_idx, knn_K)\n",
    "# for i in pred_type_embed[0]:\n",
    "#     print(types_embed_labels[i])\n",
    "print(tokenizer.convert_ids_to_tokens(pred_type_embed[0][0]))\n",
    "print(pred_type_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daeffc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b898463808f7de9d8eed8bf188ff18ea42a72c5d898f7e9a1365e818ae4a9ee4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
